â† [æ•…éšœæ’é™¤](troubleshooting.md) | [æ–‡æ¡£é¦–é¡µ](../README.md) | [English Version](../en/examples.md) â†’

# ğŸš€ ç¤ºä¾‹å’Œç”¨ä¾‹

Easy Mic é›†æˆçš„çœŸå®ä¸–ç•Œå®ç°å’Œæ¨¡å¼ã€‚ä»è§£å†³å¸¸è§éŸ³é¢‘å½•åˆ¶æŒ‘æˆ˜çš„å®Œæ•´ç¤ºä¾‹ä¸­å­¦ä¹ ã€‚

## ğŸ™ï¸ åŸºç¡€å½•éŸ³ç¤ºä¾‹

### ç®€å•è¯­éŸ³å½•éŸ³
æœ€åŸºæœ¬çš„è¯­éŸ³å½•éŸ³å®ç°ï¼š

```csharp
using UnityEngine;
using Eitan.EasyMic;

public class SimpleVoiceRecorder : MonoBehaviour
{
    private RecordingHandle _recordingHandle;
    private AudioWorkerBlueprint _bpCapture;
    
    [Header("å½•éŸ³è®¾ç½®")]
    public SampleRate sampleRate = SampleRate.Hz16000;
    public float maxDuration = 10f;
    
    void Start()
    {
        // ç¡®ä¿æƒé™
        if (!PermissionUtils.HasPermission())
        {
            Debug.LogError("âŒ æœªæˆäºˆéº¦å…‹é£æƒé™");
            return;
        }
        
        StartRecording();
    }
    
    private void StartRecording()
    {
        // åˆ·æ–°è®¾å¤‡å¹¶å¼€å§‹å½•éŸ³
        EasyMicAPI.Refresh();
        _recordingHandle = EasyMicAPI.StartRecording(sampleRate);
        
        if (_recordingHandle.IsValid)
        {
            // é€šè¿‡è“å›¾æ·»åŠ æ•è·å™¨ä¿å­˜éŸ³é¢‘
            _bpCapture = new AudioWorkerBlueprint(() => new AudioCapturer((int)maxDuration), key: "capture");
            EasyMicAPI.AddProcessor(_recordingHandle, _bpCapture);
            
            Debug.Log($"ğŸ™ï¸ ä½¿ç”¨ {_recordingHandle.Device.Name} å¼€å§‹å½•éŸ³");
        }
        else
        {
            Debug.LogError("âŒ å½•éŸ³å¯åŠ¨å¤±è´¥");
        }
    }
    
    public void StopRecording()
    {
        if (_recordingHandle.IsValid)
        {
            EasyMicAPI.StopRecording(_recordingHandle);
            
            // è·å–å½•åˆ¶çš„éŸ³é¢‘
            var capturer = EasyMicAPI.GetProcessor<AudioCapturer>(_recordingHandle, _bpCapture);
            AudioClip clip = capturer?.GetCapturedAudioClip();
            if (clip != null)
            {
                Debug.Log($"âœ… å½•åˆ¶äº† {clip.length:F1}s éŸ³é¢‘");
                
                // æ’­æ”¾å½•éŸ³
                var audioSource = GetComponent<AudioSource>();
                if (audioSource == null)
                    audioSource = gameObject.AddComponent<AudioSource>();
                    
                audioSource.clip = clip;
                audioSource.Play();
            }
        }
    }
    
    void OnDestroy()
    {
        if (_recordingHandle.IsValid)
            EasyMicAPI.StopRecording(_recordingHandle);
        // ä¼šè¯ç»“æŸä¼šè‡ªåŠ¨é‡Šæ”¾å¤„ç†å™¨
    }
}
```

### é«˜è´¨é‡ç«‹ä½“å£°å½•éŸ³
ç”¨äºéŸ³ä¹æˆ–é«˜ä¿çœŸåº”ç”¨ï¼š

```csharp
public class HiFiRecorder : MonoBehaviour
{
    private RecordingHandle _handle;
    private AudioWorkerBlueprint _bpCapture;
    
    void Start()
    {
        // ä½¿ç”¨æœ€é«˜è´¨é‡è®¾ç½®
        EasyMicAPI.Refresh();
        
        // æ‰¾åˆ°æœ€ä½³å¯ç”¨è®¾å¤‡
        var devices = EasyMicAPI.Devices;
        var bestDevice = devices.FirstOrDefault(d => d.MaxChannels >= 2) ?? devices[0];
        
        // å¼€å§‹é«˜è´¨é‡å½•éŸ³
        _handle = EasyMicAPI.StartRecording(
            bestDevice,
            SampleRate.Hz48000,  // ä¸“ä¸šå“è´¨
            Channel.Stereo       // å®Œæ•´ç«‹ä½“å£°æ•è·
        );
        
        if (_handle.IsValid)
        {
            _bpCapture = new AudioWorkerBlueprint(() => new AudioCapturer(60), key: "capture");
            EasyMicAPI.AddProcessor(_handle, _bpCapture);
            
            Debug.Log($"ğŸ¼ é«˜è´¨é‡å½•éŸ³ï¼š{bestDevice.Name} @ 48kHz ç«‹ä½“å£°");
        }
    }
    
    public void SaveToFile(string filename)
    {
        var capturer = EasyMicAPI.GetProcessor<AudioCapturer>(_handle, _bpCapture);
        var samples = capturer?.GetCapturedAudioSamples();
        AudioExtension.SaveWAV(filename, samples, 48000, 2);
        Debug.Log($"ğŸ’¾ ä¿å­˜åˆ° {filename}");
    }
}
```

## ğŸ”Š å®æ—¶éŸ³é¢‘å¤„ç†

### å®æ—¶è¯­éŸ³æ•ˆæœ
å¯¹è¯­éŸ³åº”ç”¨å®æ—¶æ•ˆæœï¼š

```csharp
public class LiveVoiceEffects : MonoBehaviour
{
    private RecordingHandle _handle;
    private VolumeGateFilter _noiseGate;
    private SimpleReverb _reverb;
    private PitchShifter _pitchShifter;
    private LoopbackPlayer _monitor;
    
    [Header("æ•ˆæœæ§åˆ¶")]
    [Range(-60f, 0f)]
    public float gateThreshold = -35f;
    
    [Range(0f, 1f)]
    public float reverbMix = 0.3f;
    
    [Range(0.5f, 2f)]
    public float pitchShift = 1f;
    
    [Range(0f, 1f)]
    public float monitorVolume = 0.5f;
    
    void Start()
    {
        SetupRecording();
    }
    
    void SetupRecording()
    {
        EasyMicAPI.Refresh();
        _handle = EasyMicAPI.StartRecording(SampleRate.Hz44100);
        
        if (_handle.IsValid)
        {
            // æ„å»ºæ•ˆæœé“¾
            _noiseGate = new VolumeGateFilter 
            { 
                ThresholdDb = gateThreshold,
                AttackTime = 0.001f,   // è¯­éŸ³å¿«é€Ÿå¯åŠ¨
                ReleaseTime = 0.2f     // å¹³æ»‘é‡Šæ”¾
            };
            
            _reverb = new SimpleReverb 
            { 
                Mix = reverbMix,
                RoomSize = 0.5f
            };
            
            _pitchShifter = new PitchShifter 
            { 
                PitchRatio = pitchShift 
            };
            
            _monitor = new LoopbackPlayer 
            { 
                Volume = monitorVolume 
            };
            
            // æŒ‰æœ€ä½³é¡ºåºæ·»åŠ å¤„ç†å™¨
            EasyMicAPI.AddProcessor(_handle, _noiseGate);
            EasyMicAPI.AddProcessor(_handle, _pitchShifter);
            EasyMicAPI.AddProcessor(_handle, _reverb);
            EasyMicAPI.AddProcessor(_handle, _monitor);
            
            Debug.Log("ğŸ¤ å®æ—¶è¯­éŸ³æ•ˆæœæ¿€æ´»");
        }
    }
    
    void Update()
    {
        // å®æ—¶æ›´æ–°æ•ˆæœå‚æ•°
        if (_noiseGate != null) _noiseGate.ThresholdDb = gateThreshold;
        if (_reverb != null) _reverb.Mix = reverbMix;
        if (_pitchShifter != null) _pitchShifter.PitchRatio = pitchShift;
        if (_monitor != null) _monitor.Volume = monitorVolume;
    }
}
```

### å®æ—¶éŸ³é¢‘å¯è§†åŒ–
å¯è§†åŒ–éŸ³é¢‘ç­‰çº§å’Œé¢‘ç‡å†…å®¹ï¼š

```csharp
public class AudioVisualizer : MonoBehaviour
{
    private RecordingHandle _handle;
    private VolumeAnalyzer _volumeAnalyzer;
    private SpectrumAnalyzer _spectrumAnalyzer;
    
    [Header("UIå¼•ç”¨")]
    public Slider volumeMeter;
    public Image[] spectrumBars = new Image[32];
    public Text volumeText;
    
    [Header("å¯è§†åŒ–è®¾ç½®")]
    public float volumeSmoothing = 0.3f;
    public float spectrumSmoothing = 0.5f;
    
    private float _smoothedVolume;
    private float[] _smoothedSpectrum;
    
    void Start()
    {
        _smoothedSpectrum = new float[spectrumBars.Length];
        SetupAudioAnalysis();
    }
    
    void SetupAudioAnalysis()
    {
        EasyMicAPI.Refresh();
        _handle = EasyMicAPI.StartRecording(SampleRate.Hz44100);
        
        if (_handle.IsValid)
        {
            // æ·»åŠ åˆ†æå¤„ç†å™¨
            _volumeAnalyzer = new VolumeAnalyzer();
            _spectrumAnalyzer = new SpectrumAnalyzer(spectrumBars.Length);
            
            EasyMicAPI.AddProcessor(_handle, _volumeAnalyzer);
            EasyMicAPI.AddProcessor(_handle, _spectrumAnalyzer);
            
            Debug.Log("ğŸ“Š éŸ³é¢‘å¯è§†åŒ–æ¿€æ´»");
        }
    }
    
    void Update()
    {
        if (_volumeAnalyzer == null || _spectrumAnalyzer == null) return;
        
        // æ›´æ–°éŸ³é‡è¡¨
        float currentVolume = _volumeAnalyzer.GetRMSVolume();
        _smoothedVolume = Mathf.Lerp(_smoothedVolume, currentVolume, volumeSmoothing);
        
        volumeMeter.value = _smoothedVolume;
        volumeText.text = $"{_volumeAnalyzer.GetRMSVolumeDb():F1} dB";
        
        // æ›´æ–°é¢‘è°±æ˜¾ç¤º
        var spectrum = _spectrumAnalyzer.GetSpectrum();
        for (int i = 0; i < spectrumBars.Length && i < spectrum.Length; i++)
        {
            _smoothedSpectrum[i] = Mathf.Lerp(_smoothedSpectrum[i], spectrum[i], spectrumSmoothing);
            
            // æ›´æ–°æ¡å½¢é«˜åº¦ï¼ˆå‡è®¾å‚ç›´æ¡å½¢ï¼‰
            var rectTransform = spectrumBars[i].rectTransform;
            rectTransform.sizeDelta = new Vector2(rectTransform.sizeDelta.x, _smoothedSpectrum[i] * 100f);
        }
    }
}

// æ”¯æŒåˆ†æå™¨ç±»
public class VolumeAnalyzer : AudioReader
{
    private float _rmsVolume;
    private float _peakVolume;
    
    protected override void OnAudioRead(ReadOnlySpan<float> buffer, AudioState state)
    {
        float sum = 0f;
        float peak = 0f;
        
        for (int i = 0; i < buffer.Length; i++)
        {
            float sample = Math.Abs(buffer[i]);
            sum += sample * sample;
            if (sample > peak) peak = sample;
        }
        
        _rmsVolume = MathF.Sqrt(sum / buffer.Length);
        _peakVolume = peak;
    }
    
    public float GetRMSVolume() => _rmsVolume;
    public float GetPeakVolume() => _peakVolume;
    public float GetRMSVolumeDb() => 20f * MathF.Log10(_rmsVolume + 1e-10f);
}

public class SpectrumAnalyzer : AudioReader
{
    private readonly int _fftSize;
    private readonly float[] _spectrum;
    private readonly Complex[] _fftBuffer;
    private int _bufferIndex;
    
    public SpectrumAnalyzer(int spectrumSize)
    {
        _fftSize = NextPowerOfTwo(spectrumSize * 2);
        _spectrum = new float[spectrumSize];
        _fftBuffer = new Complex[_fftSize];
    }
    
    protected override void OnAudioRead(ReadOnlySpan<float> buffer, AudioState state)
    {
        // ç®€åŒ–çš„FFTå®ç°
        // å®é™…ä½¿ç”¨ä¸­ï¼Œä½ ä¼šä½¿ç”¨é€‚å½“çš„FFTåº“
        for (int i = 0; i < buffer.Length && _bufferIndex < _fftSize; i++)
        {
            _fftBuffer[_bufferIndex] = new Complex(buffer[i], 0);
            _bufferIndex++;
        }
        
        if (_bufferIndex >= _fftSize)
        {
            // æ‰§è¡ŒFFTå¹¶æ›´æ–°é¢‘è°±
            FFT.ForwardTransform(_fftBuffer);
            
            for (int i = 0; i < _spectrum.Length; i++)
            {
                _spectrum[i] = (float)_fftBuffer[i].Magnitude;
            }
            
            _bufferIndex = 0;
        }
    }
    
    public float[] GetSpectrum() => _spectrum;
    
    private static int NextPowerOfTwo(int n)
    {
        int power = 1;
        while (power < n) power *= 2;
        return power;
    }
}
```

## ğŸ¤– è¯­éŸ³åŠ©æ‰‹é›†æˆ

### è¯­éŸ³è¯†åˆ«å‘½ä»¤
é›†æˆè¯­éŸ³è¯†åˆ«è¿›è¡Œè¯­éŸ³å‘½ä»¤ï¼š

```csharp
public class VoiceCommandSystem : MonoBehaviour
{
    private RecordingHandle _handle;
    private VolumeGateFilter _noiseGate;
    private SherpaRealtimeSpeechRecognizer _speechRecognizer;
    
    [Header("è¯­éŸ³è¯†åˆ«")]
    public string modelPath = "path/to/sherpa/model";
    public float confidenceThreshold = 0.7f;
    
    [Header("å‘½ä»¤")]
    public UnityEvent<string> OnCommandRecognized;
    
    private readonly Dictionary<string, System.Action> _commands = new Dictionary<string, System.Action>();
    
    void Start()
    {
        RegisterCommands();
        SetupSpeechRecognition();
    }
    
    void RegisterCommands()
    {
        _commands["å¼€å§‹å½•éŸ³"] = () => StartRecording();
        _commands["åœæ­¢å½•éŸ³"] = () => StopRecording();
        _commands["æ’­æ”¾éŸ³ä¹"] = () => PlayMusic();
        _commands["å¼€ç¯"] = () => ControlLights(true);
        _commands["å…³ç¯"] = () => ControlLights(false);
        _commands["å‡ ç‚¹äº†"] = () => SpeakTime();
    }
    
    void SetupSpeechRecognition()
    {
        EasyMicAPI.Refresh();
        _handle = EasyMicAPI.StartRecording(SampleRate.Hz16000); // è¯­éŸ³ä¼˜åŒ–
        
        if (_handle.IsValid)
        {
            // ç”¨äºæ›´å¥½è¯†åˆ«çš„å™ªéŸ³é—¨
            _noiseGate = new VolumeGateFilter
            {
                ThresholdDb = -30f,
                AttackTime = 0.01f,
                ReleaseTime = 0.3f
            };
            
            // è¯­éŸ³è¯†åˆ«å™¨
            _speechRecognizer = new SherpaRealtimeSpeechRecognizer(modelPath);
            _speechRecognizer.OnFinalResult += OnSpeechRecognized;
            _speechRecognizer.OnPartialResult += OnPartialSpeech;
            
            EasyMicAPI.AddProcessor(_handle, _noiseGate);
            EasyMicAPI.AddProcessor(_handle, _speechRecognizer);
            
            Debug.Log("ğŸ—£ï¸ è¯­éŸ³å‘½ä»¤ç³»ç»Ÿå°±ç»ª");
        }
    }
    
    private void OnPartialSpeech(string text)
    {
        Debug.Log($"è†å¬ä¸­ï¼š{text}");
    }
    
    private void OnSpeechRecognized(string text)
    {
        Debug.Log($"è¯†åˆ«ï¼š{text}");
        
        if (_speechRecognizer.LastConfidence < confidenceThreshold)
        {
            Debug.Log($"ç½®ä¿¡åº¦ä½ ({_speechRecognizer.LastConfidence:F2})ï¼Œå¿½ç•¥");
            return;
        }
        
        // æŸ¥æ‰¾åŒ¹é…å‘½ä»¤
        string lowerText = text.ToLower();
        foreach (var command in _commands)
        {
            if (lowerText.Contains(command.Key))
            {
                Debug.Log($"æ‰§è¡Œå‘½ä»¤ï¼š{command.Key}");
                command.Value.Invoke();
                OnCommandRecognized?.Invoke(command.Key);
                return;
            }
        }
        
        Debug.Log($"æœªçŸ¥å‘½ä»¤ï¼š{text}");
    }
    
    // å‘½ä»¤å®ç°
    private void StartRecording() => Debug.Log("â–¶ï¸ å¼€å§‹å½•éŸ³...");
    private void StopRecording() => Debug.Log("â¹ï¸ åœæ­¢å½•éŸ³...");
    private void PlayMusic() => Debug.Log("ğŸµ æ’­æ”¾éŸ³ä¹...");
    private void ControlLights(bool on) => Debug.Log($"ğŸ’¡ ç¯ {(on ? "å¼€" : "å…³")}");
    private void SpeakTime() => Debug.Log($"ğŸ• ç°åœ¨æ—¶é—´æ˜¯ {DateTime.Now:HH:mm}");
}
```

## ğŸ® æ¸¸æˆé›†æˆç¤ºä¾‹

### å¤šäººæ¸¸æˆè¯­éŸ³èŠå¤©
å®æ—¶è¯­éŸ³é€šä¿¡ï¼š

```csharp
public class VoiceChatManager : MonoBehaviourPunPV, IPunObservable
{
    private RecordingHandle _handle;
    private VolumeGateFilter _noiseGate;
    private AudioCapturer _capturer;
    private VoiceTransmitter _transmitter;
    
    [Header("è¯­éŸ³èŠå¤©è®¾ç½®")]
    public bool pushToTalk = false;
    public KeyCode talkKey = KeyCode.T;
    public float transmissionRate = 10f; // æ¯ç§’æ•°æ®åŒ…
    
    private bool _isTransmitting;
    private float _lastTransmissionTime;
    
    void Start()
    {
        if (photonView.isMine)
        {
            SetupVoiceCapture();
        }
        else
        {
            SetupVoicePlayback();
        }
    }
    
    void SetupVoiceCapture()
    {
        EasyMicAPI.Refresh();
        _handle = EasyMicAPI.StartRecording(SampleRate.Hz22050);
        
        if (_handle.IsValid)
        {
            // è¯­éŸ³ä¼˜åŒ–
            _noiseGate = new VolumeGateFilter
            {
                ThresholdDb = -40f,  // è¯­éŸ³èŠå¤©æ•æ„Ÿé—¨
                AttackTime = 0.005f,
                ReleaseTime = 0.1f
            };
            
            _capturer = new AudioCapturer(1); // 1ç§’ç¼“å†²
            _transmitter = new VoiceTransmitter(this);
            
            EasyMicAPI.AddProcessor(_handle, _noiseGate);
            EasyMicAPI.AddProcessor(_handle, _capturer);
            EasyMicAPI.AddProcessor(_handle, _transmitter);
            
            Debug.Log("ğŸ¤ è¯­éŸ³èŠå¤©æ•è·å°±ç»ª");
        }
    }
    
    void Update()
    {
        if (!photonView.isMine) return;
        
        bool shouldTransmit = !pushToTalk || Input.GetKey(talkKey);
        
        if (shouldTransmit != _isTransmitting)
        {
            _isTransmitting = shouldTransmit;
            _transmitter.SetTransmitting(shouldTransmit);
            
            Debug.Log($"ğŸ™ï¸ è¯­éŸ³ä¼ è¾“ï¼š{(shouldTransmit ? "å¼€" : "å…³")}");
        }
        
        // å®šæœŸå‘é€è¯­éŸ³æ•°æ®
        if (_isTransmitting && Time.time - _lastTransmissionTime > 1f / transmissionRate)
        {
            SendVoiceData();
            _lastTransmissionTime = Time.time;
        }
    }
    
    void SendVoiceData()
    {
        var audioData = _capturer.GetCapturedAudioSamples();
        if (audioData.Length > 0)
        {
            // å‹ç¼©å¹¶å‘é€è¯­éŸ³æ•°æ®
            byte[] compressedData = VoiceCompression.Compress(audioData);
            photonView.RPC("ReceiveVoiceData", RpcTarget.Others, compressedData);
            _capturer.Clear();
        }
    }
    
    [PunRPC]
    void ReceiveVoiceData(byte[] compressedData)
    {
        // è§£å‹å¹¶æ’­æ”¾è¯­éŸ³æ•°æ®
        float[] audioData = VoiceCompression.Decompress(compressedData);
        PlayVoiceClip(audioData);
    }
    
    void PlayVoiceClip(float[] audioData)
    {
        var audioSource = GetComponent<AudioSource>();
        if (audioSource == null) return;
        
        // åˆ›å»ºå¹¶æ’­æ”¾éŸ³é¢‘å‰ªè¾‘
        var clip = AudioExtension.CreateAudioClip(audioData, 22050, 1, "VoiceChat");
        audioSource.clip = clip;
        audioSource.Play();
    }
    
    public void OnPhotonSerializeView(PhotonStream stream, PhotonMessageInfo info)
    {
        // åŒæ­¥è¯­éŸ³ä¼ è¾“çŠ¶æ€
        if (stream.IsWriting)
        {
            stream.SendNext(_isTransmitting);
        }
        else
        {
            bool remoteTransmitting = (bool)stream.ReceiveNext();
            // æ›´æ–°UIæ˜¾ç¤ºè°åœ¨è¯´è¯
            UpdateTalkingIndicator(remoteTransmitting);
        }
    }
    
    void UpdateTalkingIndicator(bool talking)
    {
        // æ˜¾ç¤º/éšè—è¯´è¯æŒ‡ç¤ºå™¨UI
        var indicator = transform.Find("TalkingIndicator");
        if (indicator != null)
            indicator.gameObject.SetActive(talking);
    }
}
```

### è¯­éŸ³æ§åˆ¶è§’è‰²
ç”¨è¯­éŸ³å‘½ä»¤æ§åˆ¶æ¸¸æˆè§’è‰²ï¼š

```csharp
public class VoiceControlledCharacter : MonoBehaviour
{
    private RecordingHandle _handle;
    private SimpleCommandRecognizer _commandRecognizer;
    private CharacterController _characterController;
    
    [Header("ç§»åŠ¨è®¾ç½®")]
    public float moveSpeed = 5f;
    public float jumpForce = 8f;
    
    [Header("è¯­éŸ³å‘½ä»¤")]
    public float commandTimeout = 2f;
    
    private Vector3 _moveDirection;
    private bool _isGrounded;
    private float _lastCommandTime;
    
    void Start()
    {
        _characterController = GetComponent<CharacterController>();
        SetupVoiceControl();
    }
    
    void SetupVoiceControl()
    {
        EasyMicAPI.Refresh();
        _handle = EasyMicAPI.StartRecording(SampleRate.Hz16000);
        
        if (_handle.IsValid)
        {
            _commandRecognizer = new SimpleCommandRecognizer();
            _commandRecognizer.AddCommand("å‰è¿›", () => SetMovement(Vector3.forward));
            _commandRecognizer.AddCommand("åé€€", () => SetMovement(Vector3.back));
            _commandRecognizer.AddCommand("å·¦è½¬", () => SetMovement(Vector3.left));
            _commandRecognizer.AddCommand("å³è½¬", () => SetMovement(Vector3.right));
            _commandRecognizer.AddCommand("è·³è·ƒ", () => Jump());
            _commandRecognizer.AddCommand("åœæ­¢", () => Stop());
            
            _commandRecognizer.OnCommandRecognized += OnVoiceCommand;
            
            EasyMicAPI.AddProcessor(_handle, _commandRecognizer);
            Debug.Log("ğŸ® è¯­éŸ³æ§åˆ¶è§’è‰²å°±ç»ª");
        }
    }
    
    void OnVoiceCommand(string command)
    {
        Debug.Log($"è¯­éŸ³å‘½ä»¤ï¼š{command}");
        _lastCommandTime = Time.time;
    }
    
    void SetMovement(Vector3 direction)
    {
        _moveDirection = transform.TransformDirection(direction);
    }
    
    void Jump()
    {
        if (_isGrounded)
        {
            _moveDirection.y = jumpForce;
        }
    }
    
    void Stop()
    {
        _moveDirection = Vector3.zero;
    }
    
    void Update()
    {
        // å¦‚æœæ²¡æœ‰æœ€è¿‘å‘½ä»¤åˆ™åœæ­¢ç§»åŠ¨
        if (Time.time - _lastCommandTime > commandTimeout)
        {
            _moveDirection.x = 0;
            _moveDirection.z = 0;
        }
        
        // åº”ç”¨é‡åŠ›
        _moveDirection.y += Physics.gravity.y * Time.deltaTime;
        
        // ç§»åŠ¨è§’è‰²
        _characterController.Move(_moveDirection * moveSpeed * Time.deltaTime);
        
        // æ£€æŸ¥æ˜¯å¦æ¥åœ°
        _isGrounded = _characterController.isGrounded;
        if (_isGrounded && _moveDirection.y < 0)
            _moveDirection.y = 0;
    }
}

// åŸºäºç®€å•æ¨¡å¼çš„å‘½ä»¤è¯†åˆ«å™¨
public class SimpleCommandRecognizer : AudioReader
{
    public event System.Action<string> OnCommandRecognized;
    
    private readonly Dictionary<string, System.Action> _commands = new Dictionary<string, System.Action>();
    private readonly List<float> _audioBuffer = new List<float>();
    private float _lastAnalysisTime;
    private const float AnalysisInterval = 0.5f;
    
    public void AddCommand(string pattern, System.Action action)
    {
        _commands[pattern.ToLower()] = action;
    }
    
    protected override void OnAudioRead(ReadOnlySpan<float> buffer, AudioState state)
    {
        // æ”¶é›†éŸ³é¢‘ç”¨äºåˆ†æ
        for (int i = 0; i < buffer.Length; i++)
            _audioBuffer.Add(buffer[i]);
        
        // å®šæœŸåˆ†æ
        if (Time.time - _lastAnalysisTime > AnalysisInterval)
        {
            AnalyzeForCommands();
            _lastAnalysisTime = Time.time;
        }
    }
    
    void AnalyzeForCommands()
    {
        if (_audioBuffer.Count == 0) return;
        
        // åŸºäºç®€å•èƒ½é‡çš„å‘½ä»¤æ£€æµ‹
        float energy = 0f;
        foreach (float sample in _audioBuffer)
            energy += sample * sample;
        energy /= _audioBuffer.Count;
        
        if (energy > 0.01f) // æ£€æµ‹åˆ°è¯­éŸ³
        {
            // åœ¨çœŸå®å®ç°ä¸­ï¼Œä½ ä¼šä½¿ç”¨å®é™…çš„è¯­éŸ³è¯†åˆ«
            // å¯¹äºè¿™ä¸ªç¤ºä¾‹ï¼Œæˆ‘ä»¬å°†æ¨¡æ‹Ÿå‘½ä»¤è¯†åˆ«
            var recognizedCommand = SimulateCommandRecognition(energy);
            if (!string.IsNullOrEmpty(recognizedCommand))
            {
                if (_commands.TryGetValue(recognizedCommand, out var action))
                {
                    action.Invoke();
                    OnCommandRecognized?.Invoke(recognizedCommand);
                }
            }
        }
        
        _audioBuffer.Clear();
    }
    
    string SimulateCommandRecognition(float energy)
    {
        // åŸºäºèƒ½é‡ç­‰çº§çš„ç®€åŒ–å‘½ä»¤æ¨¡æ‹Ÿ
        // å®é™…ä½¿ç”¨ä¸­ï¼Œä½ ä¼šä½¿ç”¨é€‚å½“çš„è¯­éŸ³è¯†åˆ«ç³»ç»Ÿ
        var commands = _commands.Keys.ToArray();
        if (commands.Length > 0)
        {
            int index = Mathf.FloorToInt(energy * 100) % commands.Length;
            return commands[index];
        }
        return null;
    }
}
```

## ğŸ“± å¹³å°ç‰¹å®šç¤ºä¾‹

### Android è¯­éŸ³ç¬”è®°åº”ç”¨
ä¸ºç§»åŠ¨å½•éŸ³ä¼˜åŒ–ï¼š

```csharp
public class AndroidVoiceNotes : MonoBehaviour
{
    private RecordingHandle _handle;
    private AudioCapturer _capturer;
    private VolumeGateFilter _noiseGate;
    
    [Header("ç§»åŠ¨ä¼˜åŒ–")]
    public bool adaptiveBitrate = true;
    public bool backgroundRecording = true;
    
    void Start()
    {
        #if UNITY_ANDROID
        SetupMobileRecording();
        #endif
    }
    
    void SetupMobileRecording()
    {
        // ç¡®ä¿æƒé™
        if (!PermissionUtils.HasPermission())
        {
            Debug.LogError("âŒ æœªæˆäºˆéº¦å…‹é£æƒé™");
            return;
        }
        
        StartMobileOptimizedRecording();
    }
    
    void StartMobileOptimizedRecording()
    {
        // ä¸ºç§»åŠ¨è®¾å¤‡ç”µæ± å¯¿å‘½å’Œå¸¦å®½ä¼˜åŒ–
        SampleRate rate = adaptiveBitrate ? SampleRate.Hz16000 : SampleRate.Hz22050;
        
        EasyMicAPI.Refresh();
        _handle = EasyMicAPI.StartRecording(rate, Channel.Mono);
        
        if (_handle.IsValid)
        {
            // ç§»åŠ¨ä¼˜åŒ–å™ªéŸ³é—¨
            _noiseGate = new VolumeGateFilter
            {
                ThresholdDb = -25f,  // ç§»åŠ¨ç¯å¢ƒæ›´é«˜é˜ˆå€¼
                AttackTime = 0.01f,
                ReleaseTime = 0.3f
            };
            
            _capturer = new AudioCapturer(300); // æœ€å¤š5åˆ†é’Ÿ
            
            EasyMicAPI.AddProcessor(_handle, _noiseGate);
            EasyMicAPI.AddProcessor(_handle, _capturer);
            
            Debug.Log("ğŸ“± ç§»åŠ¨è¯­éŸ³å½•éŸ³æ¿€æ´»");
        }
    }
    
    void OnApplicationPause(bool pauseStatus)
    {
        if (backgroundRecording) return;
        
        if (pauseStatus)
        {
            // åº”ç”¨è¿›å…¥åå°æ—¶æš‚åœå½•éŸ³
            if (_handle.IsValid)
                EasyMicAPI.StopRecording(_handle);
        }
        else
        {
            // åº”ç”¨è¿”å›å‰å°æ—¶æ¢å¤å½•éŸ³
            if (!_handle.IsValid)
                StartMobileOptimizedRecording();
        }
    }
    
    public void SaveVoiceNote(string filename)
    {
        #if UNITY_ANDROID
        // ä¿å­˜åˆ°Androidå¤–éƒ¨å­˜å‚¨
        string path = Path.Combine(Application.persistentDataPath, "VoiceNotes");
        Directory.CreateDirectory(path);
        
        var samples = _capturer.GetCapturedAudioSamples();
        string fullPath = Path.Combine(path, filename + ".wav");
        
        AudioExtension.SaveWAV(fullPath, samples, 16000, 1);
        Debug.Log($"ğŸ’¾ è¯­éŸ³ç¬”è®°å·²ä¿å­˜ï¼š{fullPath}");
        
        // é€šçŸ¥Androidåª’ä½“æ‰«æå™¨
        NotifyAndroidMediaScanner(fullPath);
        #endif
    }
    
    void NotifyAndroidMediaScanner(string filePath)
    {
        #if UNITY_ANDROID && !UNITY_EDITOR
        using (var unityPlayer = new AndroidJavaClass("com.unity3d.player.UnityPlayer"))
        using (var activity = unityPlayer.GetStatic<AndroidJavaObject>("currentActivity"))
        using (var intent = new AndroidJavaObject("android.content.Intent", "android.intent.action.MEDIA_SCANNER_SCAN_FILE"))
        {
            var uri = AndroidJavaClass.CallStatic<AndroidJavaObject>("android.net.Uri", "parse", "file://" + filePath);
            intent.Call<AndroidJavaObject>("setData", uri);
            activity.Call("sendBroadcast", intent);
        }
        #endif
    }
}
```

## ğŸ” ä¸‹ä¸€æ­¥

å°†è¿™äº›æ¨¡å¼åº”ç”¨åˆ°ä½ è‡ªå·±çš„é¡¹ç›®ï¼š

- **[æœ€ä½³å®è·µ](best-practices.md)** - ä¼˜åŒ–æŠ€æœ¯
- **[æ•…éšœæ’é™¤](troubleshooting.md)** - å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ  
- **[API å‚è€ƒ](api-reference.md)** - å®Œæ•´çš„APIæ–‡æ¡£

---

â† [æ•…éšœæ’é™¤](troubleshooting.md) | **è¿”å› [æ–‡æ¡£é¦–é¡µ](../README.md)** â†’
